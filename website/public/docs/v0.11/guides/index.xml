<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Guides on Talos Linux</title>
    <link>https://talos.dev/docs/v0.11/guides/</link>
    <description>Recent content in Guides on Talos Linux</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://talos.dev/docs/v0.11/guides/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Advanced Networking</title>
      <link>https://talos.dev/docs/v0.11/guides/advanced-networking/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/advanced-networking/</guid>
      <description>Static Addressing Static addressing is comprised of specifying cidr, routes ( remember to add your default gateway ), and interface. Most likely you&amp;rsquo;ll also want to define the nameservers so you have properly functioning DNS.
machine:  network:  hostname: talos  nameservers:  - 10.0.0.1  interfaces:  - interface: eth0  cidr: 10.0.0.201/8  mtu: 8765  routes:  - network: 0.0.0.0/0  gateway: 10.0.0.1  - interface: eth1  ignore: true  time:  servers:  - time.</description>
    </item>
    
    <item>
      <title>Air-gapped Environments</title>
      <link>https://talos.dev/docs/v0.11/guides/air-gapped/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/air-gapped/</guid>
      <description>In this guide we will create a Talos cluster running in an air-gapped environment with all the required images being pulled from an internal registry. We will use the QEMU provisioner available in talosctl to create a local cluster, but the same approach could be used to deploy Talos in bigger air-gapped networks.
Requirements The follow are requirements for this guide:
 Docker 18.03 or greater Requirements for the Talos QEMU cluster  Identifying Images In air-gapped environments, access to the public Internet is restricted, so Talos can&amp;rsquo;t pull images from public Docker registries (docker.</description>
    </item>
    
    <item>
      <title>Configuring Certificate Authorities</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-certificate-authorities/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-certificate-authorities/</guid>
      <description>Appending the Certificate Authority Put into each machine the PEM encoded certificate:
machine:  ...  files:  - content: |-----BEGIN CERTIFICATE----- ... -----END CERTIFICATE-----  permissions: 0644  path: /etc/ssl/certs/ca-certificates  op: append </description>
    </item>
    
    <item>
      <title>Configuring Containerd</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-containerd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-containerd/</guid>
      <description>The base containerd configuration expects to merge in any additional configs present in /var/cri/conf.d/*.toml.
An example of exposing metrics Into each machine config, add the following:
machine:  ...  files:  - content: |[metrics] address = &amp;#34;0.0.0.0:11234&amp;#34;  path: /var/cri/conf.d/metrics.toml  op: create Create cluster like normal and see that metrics are now present on this port:
$ curl 127.0.0.1:11234/v1/metrics # HELP container_blkio_io_service_bytes_recursive_bytes The blkio io service bytes recursive # TYPE container_blkio_io_service_bytes_recursive_bytes gauge container_blkio_io_service_bytes_recursive_bytes{container_id=&amp;#34;0677d73196f5f4be1d408aab1c4125cf9e6c458a4bea39e590ac779709ffbe14&amp;#34;,device=&amp;#34;/dev/dm-0&amp;#34;,major=&amp;#34;253&amp;#34;,minor=&amp;#34;0&amp;#34;,namespace=&amp;#34;k8s.</description>
    </item>
    
    <item>
      <title>Configuring Corporate Proxies</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-corporate-proxies/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-corporate-proxies/</guid>
      <description>Appending the Certificate Authority of MITM Proxies Put into each machine the PEM encoded certificate:
machine:  ...  files:  - content: |-----BEGIN CERTIFICATE----- ... -----END CERTIFICATE-----  permissions: 0644  path: /etc/ssl/certs/ca-certificates  op: append Configuring a Machine to Use the Proxy To make use of a proxy:
machine:  env:  http_proxy: &amp;lt;http proxy&amp;gt;  https_proxy: &amp;lt;https proxy&amp;gt;  no_proxy: &amp;lt;no proxy&amp;gt; Additionally, configure the DNS nameservers, and NTP servers:</description>
    </item>
    
    <item>
      <title>Configuring Network Connectivity</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-network-connectivity/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-network-connectivity/</guid>
      <description>Configuring Network Connectivity The simplest way to deploy Talos is by ensuring that all the remote components of the system (talosctl, the control plane nodes, and worker nodes) all have layer 2 connectivity. This is not always possible, however, so this page lays out the minimal network access that is required to configure and operate a talos cluster.
 Note: These are the ports required for Talos specifically, and should be configured in addition to the ports required by kuberenetes.</description>
    </item>
    
    <item>
      <title>Configuring Pull Through Cache</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-pull-through-cache/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-pull-through-cache/</guid>
      <description>In this guide we will create a set of local caching Docker registry proxies to minimize local cluster startup time.
When running Talos locally, pulling images from Docker registries might take a significant amount of time. We spin up local caching pass-through registries to cache images and configure a local Talos cluster to use those proxies. A similar approach might be used to run Talos in production in air-gapped environments. It can be also used to verify that all the images are available in local registries.</description>
    </item>
    
    <item>
      <title>Configuring the Cluster Endpoint</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-the-cluster-endpoint/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-the-cluster-endpoint/</guid>
      <description>In this section, we will step through the configuration of a Talos based Kubernetes cluster. There are three major components we will configure:
 apid and talosctl the master nodes the worker nodes  Talos enforces a high level of security by using mutual TLS for authentication and authorization.
We recommend that the configuration of Talos be performed by a cluster owner. A cluster owner should be a person of authority within an organization, perhaps a director, manager, or senior member of a team.</description>
    </item>
    
    <item>
      <title>Configuring Wireguard Network</title>
      <link>https://talos.dev/docs/v0.11/guides/configuring-wireguard-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/configuring-wireguard-network/</guid>
      <description>Configuring Wireguard Network Quick Start The quickest way to try out Wireguard is to use talosctl cluster create command:
talosctl cluster create --wireguard-cidr 10.1.0.0/24 It will automatically generate Wireguard network configuration for each node with the following network topology:
Where all controlplane nodes will be used as Wireguard servers which listen on port 51111. All controlplanes and workers will connect to all controlplanes. It also sets PersistentKeepalive to 5 seconds to establish controlplanes to workers connection.</description>
    </item>
    
    <item>
      <title>Converting Control Plane</title>
      <link>https://talos.dev/docs/v0.11/guides/converting-control-plane/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/converting-control-plane/</guid>
      <description>Talos version 0.9 runs Kubernetes control plane in a new way: static pods managed by Talos. Talos version 0.8 and below runs self-hosted control plane. After Talos OS upgrade to version 0.9 Kubernetes control plane should be converted to run as static pods.
This guide describes automated conversion script and also shows detailed manual conversion process.
Video Walkthrough To see a live demo of this writeup, see the video below:</description>
    </item>
    
    <item>
      <title>Customizing the Kernel</title>
      <link>https://talos.dev/docs/v0.11/guides/customizing-the-kernel/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/customizing-the-kernel/</guid>
      <description>The installer image contains ONBUILD instructions that handle the following:
 the decompression, and unpacking of the initramfs.xz the unsquashing of the rootfs the copying of new rootfs files the squashing of the new rootfs and the packing, and compression of the new initramfs.xz  When used as a base image, the installer will perform the above steps automatically with the requirement that a customization stage be defined in the Dockerfile.</description>
    </item>
    
    <item>
      <title>Customizing the Root Filesystem</title>
      <link>https://talos.dev/docs/v0.11/guides/customizing-the-root-filesystem/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/customizing-the-root-filesystem/</guid>
      <description>The installer image contains ONBUILD instructions that handle the following:
 the decompression, and unpacking of the initramfs.xz the unsquashing of the rootfs the copying of new rootfs files the squashing of the new rootfs and the packing, and compression of the new initramfs.xz  When used as a base image, the installer will perform the above steps automatically with the requirement that a customization stage be defined in the Dockerfile.</description>
    </item>
    
    <item>
      <title>Deploying Metrics Server</title>
      <link>https://talos.dev/docs/v0.11/guides/deploy-metrics-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/deploy-metrics-server/</guid>
      <description>Metrics Server enables use of the Horizontal Pod Autoscaler and Vertical Pod Autoscaler. It does this by gathering metrics data from the kubelets in a cluster. By default, the certificates in use by the kubelets will not be recognized by metrics-server. This can be solved by either configuring metrics-server to do no validation of the TLS certificates, or by modifying the kubelet configuration to rotate its certificates and use ones that will be recognized by metrics-server.</description>
    </item>
    
    <item>
      <title>Disaster Recovery</title>
      <link>https://talos.dev/docs/v0.11/guides/disaster-recovery/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/disaster-recovery/</guid>
      <description>etcd database backs Kubernetes control plane state, so if the etcd service is unavailable Kubernetes control plane goes down, and the cluster is not recoverable until etcd is recovered with contents. The etcd consistency model builds around the consensus protocol Raft, so for highly-available control plane clusters, loss of one control plane node doesn&amp;rsquo;t impact cluster health. In general, etcd stays up as long as a sufficient number of nodes to maintain quorum are up.</description>
    </item>
    
    <item>
      <title>Disk Encryption</title>
      <link>https://talos.dev/docs/v0.11/guides/disk-encryption/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/disk-encryption/</guid>
      <description>It is possible to enable encryption for system disks at the OS level. As of this writing, only STATE and EPHEMERAL partitions can be encrypted. STATE contains the most sensitive node data: secrets and certs. EPHEMERAL partition may contain some sensitive workload data. Data is encrypted using LUKS2, which is provided by the Linux kernel modules and cryptsetup utility. The operating system will run additional setup steps when encryption is enabled.</description>
    </item>
    
    <item>
      <title>Editing Machine Configuration</title>
      <link>https://talos.dev/docs/v0.11/guides/editing-machine-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/editing-machine-configuration/</guid>
      <description>Talos node state is fully defined by machine configuration. Initial configuration is delivered to the node at bootstrap time, but configuration can be updated while the node is running.
 Note: Be sure that config is persisted so that configuration updates are not overwritten on reboots. Configuration persistence was enabled by default since Talos 0.5 (persist: true in machine configuration).
 There are three talosctl commands which facilitate machine configuration updates:</description>
    </item>
    
    <item>
      <title>Managing PKI</title>
      <link>https://talos.dev/docs/v0.11/guides/managing-pki/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/managing-pki/</guid>
      <description>Generating an Administrator Key Pair In order to create a key pair, you will need the root CA.
Save the the CA public key, and CA private key as ca.crt, and ca.key respectively. Now, run the following commands to generate a certificate:
talosctl gen key --name admin talosctl gen csr --key admin.key --ip 127.0.0.1 talosctl gen crt --ca ca --csr admin.csr --name admin Now, base64 encode admin.crt, and admin.key:
cat admin.</description>
    </item>
    
    <item>
      <title>Resetting a Machine</title>
      <link>https://talos.dev/docs/v0.11/guides/resetting-a-machine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/resetting-a-machine/</guid>
      <description>From time to time, it may be beneficial to reset a Talos machine to its &amp;ldquo;original&amp;rdquo; state. Bear in mind that this is a destructive action for the given machine. Doing this means removing the machine from Kubernetes, Etcd (if applicable), and clears any data on the machine that would normally persist a reboot.
The API command for doing this is talosctl reset. There are a couple of flags as part of this command:</description>
    </item>
    
    <item>
      <title>Role-based access control (RBAC)</title>
      <link>https://talos.dev/docs/v0.11/guides/rbac/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/rbac/</guid>
      <description>Talos v0.11 introduced initial support for role-based access control (RBAC). This guide will explain what that is and how to enable it without losing access to the cluster.
RBAC in Talos Talos uses certificates to authorize users. The certificate subject&amp;rsquo;s organization field is used to encode user roles. There is a set of predefined roles that allow access to different API methods:
 os:admin grants access to all methods; os:reader grants access to &amp;ldquo;safe&amp;rdquo; methods (for example, that includes the ability to list files, but does not include the ability to read files content); os:etcd:backup grants access to /machine.</description>
    </item>
    
    <item>
      <title>Storage</title>
      <link>https://talos.dev/docs/v0.11/guides/storage/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/storage/</guid>
      <description>In Kubernetes, using storage in the right way is well-facilitated by the API.
However, unless you are running in a major public cloud, that API may not be hooked up to anything. This frequently sends users down a rabbit hole of researching all the various options for storage backends for their platform, for Kubernetes, and for their workloads. There are a lot of options out there, and it can be fairly bewildering.</description>
    </item>
    
    <item>
      <title>Troubleshooting Control Plane</title>
      <link>https://talos.dev/docs/v0.11/guides/troubleshooting-control-plane/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/troubleshooting-control-plane/</guid>
      <description>This guide is written as series of topics and detailed answers for each topic. It starts with basics of control plane and goes into Talos specifics.
This document mostly applies only to Talos 0.9 control plane based on static pods. If Talos was upgraded from version 0.8, it might be still running self-hosted control plane, current status can be checked with the command talosctl get bootstrapstatus:
$ talosctl -n &amp;lt;IP&amp;gt; get bs NODE NAMESPACE TYPE ID VERSION SELF HOSTED 172.</description>
    </item>
    
    <item>
      <title>Upgrading Kubernetes</title>
      <link>https://talos.dev/docs/v0.11/guides/upgrading-kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/upgrading-kubernetes/</guid>
      <description>This guide covers Kubernetes control plane upgrade for clusters running Talos-managed control plane. If the cluster is still running self-hosted control plane (after upgrade from Talos 0.8), please refer to 0.8 docs.
Video Walkthrough To see a live demo of this writeup, see the video below:
Automated Kubernetes Upgrade To upgrade from Kubernetes v1.20.1 to v1.20.4 run:
$ talosctl --nodes &amp;lt;master node&amp;gt; upgrade-k8s --from 1.20.1 --to 1.20.4 discovered master nodes [&amp;#34;172.</description>
    </item>
    
    <item>
      <title>Upgrading Talos</title>
      <link>https://talos.dev/docs/v0.11/guides/upgrading-talos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/upgrading-talos/</guid>
      <description>Talos upgrades are effected by an API call. The talosctl CLI utility will facilitate this.
Video Walkthrough To see a live demo of this writeup, see the video below:
Upgrading from Talos 0.9 TBD
After Upgrade to 0.10 TBD
After Upgrade to 0.11 TBD
talosctl Upgrade To manually upgrade a Talos node, you will specify the node&amp;rsquo;s IP address and the installer container image for the version of Talos to which you wish to upgrade.</description>
    </item>
    
    <item>
      <title>Virtual (shared) IP</title>
      <link>https://talos.dev/docs/v0.11/guides/vip/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://talos.dev/docs/v0.11/guides/vip/</guid>
      <description>One of the biggest pain points when building a high-availability controlplane is giving clients a single IP or URL at which they can reach any of the controlplane nodes. The most common approaches all require external resources: reverse proxy, load balancer, BGP, and DNS.
Using a &amp;ldquo;Virtual&amp;rdquo; IP address, on the other hand, provides high availability without external coordination or resources, so long as the controlplane members share a layer 2 network.</description>
    </item>
    
  </channel>
</rss>
